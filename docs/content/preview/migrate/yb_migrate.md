---
title: Database Migration Engine
headerTitle: Database Migration Engine
linkTitle: Database Migration Engine
description: Overview of the yb_migrate database engine for migrating data and applications from other databases to YugabyteDB.
beta: /preview/faq/general/#what-is-the-definition-of-the-beta-feature-tag
menu:
  preview:
    identifier: yb-migrate
    parent: migrate
    weight: 720
isTocNested: true
showAsideToc: true
---

[yb_migrate](https://github.com/yugabyte/yb-db-migration) is an open-source database migration engine provided by YugabyteDB. It is a command line executable program that supports migrating databases from PostgreSQL, Oracle, and MySQL to a YugabyteDB database. yb_migrate addresses both steps of a database migration - schema-migration and data-migration.

{{< note title="Note" >}}

yb_migrate supports `offline` migration mode. The `online` migration mode is currently under development.
In the *offline migration* mode, the source database must not change during the migration. The offline migration is considered complete when all the requested schema objects and data are migrated to the target database.

{{< /note >}}

<!-- - In the *online migration* mode, the source database can continue to change. After the full initial migration, yb_migrate continues replicating source database changes to the target database. The process runs continuously, until you decide to switch-over to the YugabyteDB database. -->

A typical migration workflow using yb_migrate consists of the following steps:

- Install yb_migrate on a *migrator machine*.
- Generate a *Migration Assessment Report* using the `yb_migrate generateReport` command. The report suggests changes to the PostgreSQL schema to make it appropriate for YugabyteDB.
- Convert the source database schema to PostgreSQL format using the `yb_migrate export schema` command.
- Manually change the exported schema as suggested in the Migration Assessment Report.
- Dump the source database in the local files on the migrator machine using the `yb_migrate export data` command.
- Import the schema in the target YugabyteDB database using the `yb_migrate import schema` command.
- Import the data in the target YugabyteDB database using the `yb_migrate import data` command.

<!-- [Diagram] needs to go here-->

## How does yb_migrate work?

<!-- yb_migrate is installed on a *migrator machine*. -->

<!-- - Runs CentOS or Ubuntu.
- Can reach both source and target DB.
- Has local storage of at least 1.5 times the size of source DB. -->

yb_migrate keeps all of its migration state, including exported schema and data, in a local directory called *export directory*. Before starting migration, you should create the directory on a file system that has enough space to keep the entire data dump. Next, you should provide the path of the export directory as a mandatory argument (`--export-dir`) to each invocation of the yb_migrate command.

The export directory has the following sub-directories and files:

- `reports` directory contains the generated Migration Assessment Report.
- `schema` directory contains the source database schema translated to PostgreSQL. The schema is partitioned into smaller files by the schema object type such as tables, views, and so on.
- `data` directory contains TSV (Tab Separated Values) files that are passed to the COPY command on the target database.
- `metainfo` and `temp` directories are used by yb_migrate for internal bookkeeping.
- `yb_migrate.log` contains log messages.

In the *export phase*, yb_migrate uses `ora2pg` (for Oracle and MySQL) or `pg_dump` (for PostgreSQL) to dump schema and data in the PostgreSQL format. Given that YugabyteDB is a distributed database and uses storage format different from PostgreSQL, minor manual changes are required to the PostgreSQL schema dumped by yb_migrate. The report generated by the `yb_migrate generateReport` command, points to various schema files that you should manually change before trying to import the schema.

In the *import schema phase*, yb_migrate applies the DDL SQL files located in the `$EXPORT_DIR/schema` directory to the target database.

In the *import data phase*, yb_migrate splits the data dump files from the `$EXPORT_DIR/data` directory into smaller *batches* ,each of which contains at most `--batch-size` number of records. yb_migrate concurrently ingests the batches such that all nodes of the target YugabyteDB cluster are utilized. The import data phase is designed to be *restartable*; if yb_migrate terminates when the data import was in progress, upon restart the data import resumes from its state in the previous run.

<!-- ## Limitations - Don't think there's need to add limitations

- yb_migrate doesn't yet support following features:

  - BLOB and CLOB
  - TABLESPACEs
  - ALTER VIEW -->

## Installation

### Machine requirements

The machine where you'll run the yb_migrate command should:

- run CentOS or Ubuntu.
- connect to both the source and target database.
- have local storage at least 1.5 times the size of source DB.
- have sudo access.

Set up a machine where you can run yb_migrate using the following steps:

- Clone the yb_migrate repository.

```sh
git clone https://github.com/yugabyte/yb-db-migration.git
```

- Change the directory to `yb-db-migration/installer_scripts`.

```sh
cd yb-db-migration/installer_scripts
```

- Depending on the Linux distribution (CentOS or Ubuntu)  you're running, execute the appropriate installer script:

```sh
//CentOS
./yb_migrate_installer__centos.sh

//Ubuntu
./yb_migrate_installer__ubuntu.sh
```

It is safe to execute the script multiple times. On each run, the script regenerates the `yb_migrate` executable based on the latest commit in the git repository. If the script fails for some reason, check the `yb_migrate_installer.log` in the current working directory.

- The script generates a `.yb_migrate_installer_bashrc` file in the home directory. Source the file to ensure that the correct environment variables are set.

```sh
source ~/.yb_migrate_installer_bashrc
```

- Check that yb_migrate is installed using the following command:

```sh
yb_migrate --help
```

## Database Migration Process

Migrate from the source database to the target database using the following steps:

<!-- - Prepare the source database.
- Prepare the target database.
- Generate report.
- Export schema.
- Manually edit schema.
- Export data.
- Import schema.
- Import data.
- Verify target database. -->
<!--
Following sections provide details of each of the above steps. -->

### Prepare the source database

- Create a database user and provide the user with READ access to all the resources which need to be migrated. For PostgreSQL and MySQL, yb_migrate also needs READ access on tables/views from the `information_schema`.

- You'll need to provide the user and the source database details in the subsequent invocations of yb_migrate. For convenience, you can populate the information in the following environment variables:

```sh
export SOURCE_DB_TYPE=oracle
export SOURCE_DB_HOST=localhost
export SOURCE_DB_PORT=1521
export SOURCE_DB_USER=sakila
export SOURCE_DB_PASSWORD=password
export SOURCE_DB_NAME=pdb1
export SOURCE_DB_SCHEMA=sakila
```

Replace values of the above environment variables as per your database details. SOURCE_DB_TYPE can be one of [`postgresql`, `mysql`, `oracle`].

- If you want yb_migrate to connect to the source database over SSL, refer to [SSL Connectivity](#ssl-connectivity) in the References section.

### Prepare the target database

- Create the target database in the YugabyteDB cluster. The database name can be the same or different from the source database name. If the target database name is not provided, yb_migrate assumes the same name as the source database.

```sql
CREATE DATABASE sakila;
```

- For convenience, capture the database name in an environment variable.

```sh
export TARGET_DB_NAME=sakila
```

- Create a role with the superuser privileges. yb_migrate will use the role to connect to the target database. Capture the user and database details in environment variables.

```sh
export TARGET_DB_HOST=127.0.0.1
export TARGET_DB_PORT=5433
export TARGET_DB_USER=yugabyte
export TARGET_DB_PASSWORD=password
```

By default, yb_migrate creates tables in the `public` schema. To migrate the database in a non-public schema, you should provide the name of the target schema and yb_migrate takes care of creating it.

- If you want yb_migrate to connect to the target database over SSL, refer to [SSL Connectivity](#ssl-connectivity) in the References section.

### Create an export directory

Create an export directory in the local file system on the migrator machine. yb_migrate uses the directory to store source data, schema files, and migration state. The file system in which the directory resides must have enough free space to hold the entire source database. Create the directory and place its path in an environment variable.

```sh
mkdir -p ~/export-dirs/sakila
export EXPORT_DIR=~/export-dirs/sakila
```

### Generate report

<!-- Using `ora2pg` and `pg_dump`, yb_migrate can extract and convert the source database schema to an equivalent PostgreSQL schema. The schema may not be suitable yet, to be imported into YugabyteDB and may require minor changes. -->

<!-- Refer [this document](#https://docs.google.com/document/d/1jCLiHDEHiYpgVObILDC_2Ormr-Kx36YhkqHXUCVGO1Q/edit#) to know more about modeling data for YugabyteDB
The above doc needs to be into a new page-->

The `yb_migrate generateReport` command analyses the PostgreSQL schema and prepares a report that lists the DDL statements that need changes. Here is a sample invocation of the command:

```sh
yb_migrate generateReport --export-dir ${EXPORT_DIR} \
        --source-db-type ${SOURCE_DB_TYPE} \
        --source-db-host ${SOURCE_DB_HOST} \
        --source-db-user ${SOURCE_DB_USER} \
        --source-db-password ${SOURCE_DB_PASSWORD} \
        --source-db-name ${SOURCE_DB_NAME} \
        --source-db-schema ${SOURCE_DB_SCHEMA} \
        --output-format txt
```

The `--output-format` can be `html`, `txt`, `json`, or `xml`.

The above command generates a report file under `EXPORT_DIR/reports/`.

### Export schema

The `yb_migrate export schema` command extracts the schema from the source database, converts it into PostgreSQL format (if the source database is Oracle or MySQL), and dumps the SQL DDL files in the `EXPORT_DIR/schema/*` directories. Here is a sample invocation of the command:

```sh
yb_migrate export schema --export-dir ${EXPORT_DIR} \
        --source-db-type ${SOURCE_DB_TYPE} \
        --source-db-host ${SOURCE_DB_HOST} \
        --source-db-user ${SOURCE_DB_USER} \
        --source-db-password ${SOURCE_DB_PASSWORD} \
        --source-db-name ${SOURCE_DB_NAME} \
        --source-db-schema ${SOURCE_DB_SCHEMA}
```

### Manually edit the schema

Fix all the issues listed in the generated migration report by manually editing the SQL DDL files from the `EXPORT_DIR/schema/*`.

### Export data

Run the `yb_migrate export data` command to dump the source data into the `EXPORT_DIR/data` directory.

```sh
yb_migrate export data --export-dir ${EXPORT_DIR} \
        --source-db-type ${SOURCE_DB_TYPE} \
        --source-db-host ${SOURCE_DB_HOST} \
        --source-db-user ${SOURCE_DB_USER} \
        --source-db-password ${SOURCE_DB_PASSWORD} \
        --source-db-name ${SOURCE_DB_NAME} \
        --source-db-schema ${SOURCE_DB_SCHEMA}
```

The options passed to the command are similar to the `export schema` command. To export only a subset of the tables, pass a comma separated list of table names in the `--table-list` argument. To speed up the data export of larger source databases, you can pass values greater than 1 to the `--parallel-jobs` argument. It will cause yb_migrate to dump multiple tables concurrently.

### Import the schema

Use the `yb_migrate import schema` command to import the schema.

```sh
yb_migrate import schema --export-dir ${EXPORT_DIR} \
        --target-db-host ${TARGET_DB_HOST} \
        --target-db-port ${TARGET_DB_PORT} \
        --target-db-user ${TARGET_DB_USER} \
        --target-db-password ${TARGET_DB_PASSWORD:-''} \
        --target-db-name ${TARGET_DB_NAME}
```

If yb_migrate terminates before it imports the entire schema, you can rerun it by adding `--ignore-exist` option.

{{< note title="Note" >}}

The `yb_migrate import schema` command does not import indexes yet. This is done to speed up the data import phase. The indexes will be created by `yb_migrate import data` command after importing the data.

{{< /note >}}

### Import data

After you have successfully exported the source data and imported the schema in the target database, you can now import the data using the `yb_migrate import data` command:

```sh
yb_migrate import data --export-dir ${EXPORT_DIR} \
        --target-db-host ${TARGET_DB_HOST} \
        --target-db-port ${TARGET_DB_PORT} \
        --target-db-user ${TARGET_DB_USER} \
        --target-db-password ${TARGET_DB_PASSWORD:-''} \
        --target-db-name ${TARGET_DB_NAME}
```

The `yb_migrate import data` command reads data files located in the `EXPORT_DIR/data`. The command, by default, creates one database connection to each of the nodes of the target YugabyteDB cluster. You can increase the number of connections by specifying the total connection count in the `--parallel-jobs` argument. The command will equally distribute the connections among all the nodes of the cluster. It splits the larger tables into smaller chunks, each containing at most `--batch-size` number of records. By default, the `--batch-size` is 100,000 records.

Run the `yb_migrate import data status --export-dir ${EXPORT_DIR}` command to get the overall progress of the data import operation.While importing a very large database, you should run the import data command in a `screen` session, so that the import is not terminated when the terminal session stops. If the `yb_migrate import data` command terminates before it could complete the data ingestion, you can rerun it with the same arguments and the command will resume the data import operation.
After successfully loading the data, the command creates the indexes listed in the schema.

### Verify target database

After the successful execution of the `yb_migrate import data` command, the automated part of the database migration process is considered complete. You should manually run validation queries on both the source and target database to ensure that the data is correctly migrated. A sample query to validate the databases can include checking the row count in each table.
<!-- The validation queries can be as simple as checking the row count in each table or it can utilise some domain knowledge e.g. match the sum of the `amount` column in the `payments` table. -->

## References

### SSL Connectivity

You can instruct yb_migrate to connect to the source or target database over an SSL connection. Connecting securely to these databases : PostgreSQL, MySQL, and YugabyteDB requires you to pass a very similar set of arguments to the yb_migrate tool. For Oracle, on the other hand, requires a different set of arguments.

### PostgreSQL and MySQL

- `--source-ssl-mode (disable|allow|prefer|require|verify-ca|verify-full)`
    Value of this argument determines:
  - whether an encrypted connection is established between yb_migrate and the database server; and
  - whether the certificate of the database server is verified from a CA.

    Possible values and their meaning is given below:
  - `disable`: Only try a non-SSL connection.
  - `allow`: First try a non-SSL connection; if that fails, try an SSL connection. (Not supported for MySQL.)
  - `prefer` (default): First try an SSL connection; if that fails, try a non-SSL connection.
  - `require`: Only try an SSL connection. If a root CA file is present, verify the certificate in the same way as if verify-ca was specified.
  - `verify-ca`: Only try an SSL connection, and verify that the server certificate is issued by a trusted certificate authority (CA).
  - `verify-full`: Only try an SSL connection, verify that the server certificate is issued by a trusted CA and that the requested server host name matches that in the certificate.

- `--source-ssl-cert` and `--source-ssl-key`

    These two arguments specify names of the files containing SSL certificate and key, respectively. The <cert, key> pair forms the identity of the client.

- `--source-ssl-root-cert`

    This parameter specifies the path to a file containing SSL certificate authority (CA) certificate(s). If the file exists, the server's certificate will be verified to be signed by one of these authorities.

- `--source-ssl-crl`

    This parameter specifies the path to a file containing the SSL certificate revocation list (CRL). Certificates listed in this file, if it exists, will be rejected while attempting to authenticate the server's certificate.

### YugabyteDB

You need to pass following arguments to yb_migrate to establish an SSL connection with YugabyteDB:

- `--target-ssl-mode`
- `--target-ssl-cert`
- `--target-ssl-key`
- `--target-ssl-root-cert`
- `--target-ssl-crl`

Semantics of these arguments match with the similarly named arguments described in the previous section.

### Oracle

For Oracle, create a TNS alias that is configured to establish a secure connection with the server. You must then pass the TNS alias to yb_migrate as `--oracle-tns-alias` argument. yb_migrate uses the TNS alias to securely connect to the server.

When you pass the `--oracle-tns-alias` argument, you don't need to pass the `--source-db-host`, `--source-db-port`, and `--source-db-name` arguments to the yb_migrate.

## Manual Schema Changes

Some examples of manual schema changes:

- **`CREATE INDEX CONCURRENTLY` NOT SUPPORTED**:

  This feature is not supported yet in YugabyteDB. You should remove the `CONCURRENTLY` clause before trying to import the schema.

- **Primary Key cannot be added to Partitioned table using ALTER TABLE**:

  Add the primary key definition right in the `CREATE TABLE` statement itself.
